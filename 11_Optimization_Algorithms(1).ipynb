{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11. Optimization Algorithms(1)",
      "provenance": [],
      "authorship_tag": "ABX9TyP2XdfOjDsijAEzR7KgXumy"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **11.5 Minibatch Stochastic Gradient Descent**\n",
        "\n",
        "11.5.1 Vectorization and Caches"
      ],
      "metadata": {
        "id": "0h3Adut6-j_i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yWjy7VFQ-KDr"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from d2l import torch as d2l\n",
        "\n",
        "timer = d2l.Timer()\n",
        "A = torch.zeros(256, 256)\n",
        "B = torch.randn(256, 256)\n",
        "C = torch.randn(256, 256)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute A = BC one element at a time\n",
        "timer.start()\n",
        "for i in range(256):\n",
        "  for j in range(256):\n",
        "    A[i, j] = torch.dot(B[i, :], C[:, j])\n",
        "timer.stop()"
      ],
      "metadata": {
        "id": "h71KCCz7-zUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute A = BC one column at a time\n",
        "timer.start()\n",
        "for j in range(256):\n",
        "  A[:, j] = torch.mv(B, C[:, j])\n",
        "timer.stop()"
      ],
      "metadata": {
        "id": "HXVmVwiN-4og"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute A = BC in one go\n",
        "timer.start()\n",
        "A = torch.mm(B, C)\n",
        "timer.stop()\n",
        "\n",
        "# Multiply and add count as separate operations (fused in practice)\n",
        "gigaflops = [2/i for i in timer.times]\n",
        "print(f'performance in Gigaflops: element {gigaflops[0]:.3f}, '\n",
        "    f'column {gigaflops[1]:.3f}, full {gigaflops[2]:.3f}')"
      ],
      "metadata": {
        "id": "YXKWUNrJ-5sv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.5.2 Minibatches"
      ],
      "metadata": {
        "id": "bQEIFFo_--ti"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "timer.start()\n",
        "for j in range(0, 256, 64):\n",
        "A[:, j:j+64] = torch.mm(B, C[:, j:j+64])\n",
        "timer.stop()\n",
        "print(f'performance in Gigaflops: block {2 / timer.times[3]:.3f}')"
      ],
      "metadata": {
        "id": "sx6Nx2Yl-_Kt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.5.3 Reading the Dataset"
      ],
      "metadata": {
        "id": "LSNTzCS8_NjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "d2l.DATA_HUB['airfoil'] = (d2l.DATA_URL + 'airfoil_self_noise.dat',\n",
        "    '76e5be1548fd8222e5074cf0faae75edff8cf93f')\n",
        "\n",
        "#@save\n",
        "def get_data_ch11(batch_size=10, n=1500):\n",
        "  data = np.genfromtxt(d2l.download('airfoil'),\n",
        "    dtype=np.float32, delimiter='\\t')\n",
        "  data = torch.from_numpy((data - data.mean(axis=0)) / data.std(axis=0))\n",
        "  data_iter = d2l.load_array((data[:n, :-1], data[:n, -1]),\n",
        "    batch_size, is_train=True)\n",
        "  return data_iter, data.shape[1]-1"
      ],
      "metadata": {
        "id": "NDFvFn0j_Loa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.5.4 Implementation from Scratch\n"
      ],
      "metadata": {
        "id": "PDJ7JiOH_W1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd(params, states, hyperparams):\n",
        "  for p in params:\n",
        "    p.data.sub_(hyperparams['lr'] * p.grad)\n",
        "    p.grad.data.zero_()"
      ],
      "metadata": {
        "id": "VbBhDGPc_Xfp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "def train_ch11(trainer_fn, states, hyperparams, data_iter,\n",
        "  feature_dim, num_epochs=2):\n",
        "  # Initialization\n",
        "  w = torch.normal(mean=0.0, std=0.01, size=(feature_dim, 1),\n",
        "        requires_grad=True)\n",
        "  b = torch.zeros((1), requires_grad=True)\n",
        "  net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss\n",
        "  # Train\n",
        "  animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
        "      xlim=[0, num_epochs], ylim=[0.22, 0.35])\n",
        "  n, timer = 0, d2l.Timer()\n",
        "  for _ in range(num_epochs):\n",
        "    for X, y in data_iter:\n",
        "      l = loss(net(X), y).mean()\n",
        "      l.backward()\n",
        "      trainer_fn([w, b], states, hyperparams)\n",
        "      n += X.shape[0]\n",
        "      if n % 200 == 0:\n",
        "        timer.stop()\n",
        "        animator.add(n/X.shape[0]/len(data_iter),\n",
        "            (d2l.evaluate_loss(net, data_iter, loss),))\n",
        "        timer.start()\n",
        "  print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch')\n",
        "  return timer.cumsum(), animator.Y[0]"
      ],
      "metadata": {
        "id": "SegK50E7_chJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sgd(lr, batch_size, num_epochs=2):\n",
        "  data_iter, feature_dim = get_data_ch11(batch_size)\n",
        "  return train_ch11(\n",
        "    sgd, None, {'lr': lr}, data_iter, feature_dim, num_epochs)\n",
        "  \n",
        "gd_res = train_sgd(1, 1500, 10)"
      ],
      "metadata": {
        "id": "27ubgfIX_w9S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_res = train_sgd(0.005, 1)"
      ],
      "metadata": {
        "id": "XQWTk9yV_1Ny"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini1_res = train_sgd(.4, 100)"
      ],
      "metadata": {
        "id": "FhPIlvBf_3bE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mini2_res = train_sgd(.05, 10)"
      ],
      "metadata": {
        "id": "TeqXE8g4_5Va"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.set_figsize([6, 3])\n",
        "d2l.plot(*list(map(list, zip(gd_res, sgd_res, mini1_res, mini2_res))),\n",
        "  'time (sec)', 'loss', xlim=[1e-2, 10],\n",
        "  legend=['gd', 'sgd', 'batch size=100', 'batch size=10'])\n",
        "d2l.plt.gca().set_xscale('log')"
      ],
      "metadata": {
        "id": "QJMkHuvy_-mF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.5.5 Concise Implementation"
      ],
      "metadata": {
        "id": "snr7ZOUZADXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@save\n",
        "def train_concise_ch11(trainer_fn, hyperparams, data_iter, num_epochs=4):\n",
        "  # Initialization\n",
        "  net = nn.Sequential(nn.Linear(5, 1))\n",
        "  def init_weights(m):\n",
        "    if type(m) == nn.Linear:\n",
        "      torch.nn.init.normal_(m.weight, std=0.01)\n",
        "  net.apply(init_weights)\n",
        "\n",
        "  optimizer = trainer_fn(net.parameters(), **hyperparams)\n",
        "  loss = nn.MSELoss(reduction='none')\n",
        "  animator = d2l.Animator(xlabel='epoch', ylabel='loss',\n",
        "          xlim=[0, num_epochs], ylim=[0.22, 0.35])\n",
        "\n",
        "  n, timer = 0, d2l.Timer()\n",
        "  for _ in range(num_epochs):\n",
        "    for X, y in data_iter:\n",
        "      optimizer.zero_grad()\n",
        "      out = net(X)\n",
        "      y = y.reshape(out.shape)\n",
        "      l = loss(out, y)\n",
        "      l.mean().backward()\n",
        "      optimizer.step()\n",
        "      n += X.shape[0]\n",
        "      if n % 200 == 0:\n",
        "        timer.stop()\n",
        "        # `MSELoss` computes squared error without the 1/2 factor\n",
        "        animator.add(n/X.shape[0]/len(data_iter),\n",
        "            (d2l.evaluate_loss(net, data_iter, loss) / 2,))\n",
        "        timer.start()\n",
        "  print(f'loss: {animator.Y[0][-1]:.3f}, {timer.avg():.3f} sec/epoch')"
      ],
      "metadata": {
        "id": "BF6hW9LaAD2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter, _ = get_data_ch11(10)\n",
        "trainer = torch.optim.SGD\n",
        "train_concise_ch11(trainer, {'lr': 0.01}, data_iter)"
      ],
      "metadata": {
        "id": "hayUvKGNAg1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.6 Momentum**\n",
        "\n",
        "11.6.1 Basics"
      ],
      "metadata": {
        "id": "faRH40QyAkft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from d2l import torch as d2l\n",
        "eta = 0.4\n",
        "def f_2d(x1, x2):\n",
        "  return 0.1 * x1 ** 2 + 2 * x2 ** 2"
      ],
      "metadata": {
        "id": "DZkpycnUApE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gd_2d(x1, x2, s1, s2):\n",
        "  return (x1 - eta * 0.2 * x1, x2 - eta * 4 * x2, 0, 0)\n",
        "d2l.show_trace_2d(f_2d, d2l.train_2d(gd_2d))"
      ],
      "metadata": {
        "id": "afQOC1AOAqPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 0.6\n",
        "d2l.show_trace_2d(f_2d, d2l.train_2d(gd_2d))"
      ],
      "metadata": {
        "id": "V9gRnRsmAuWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def momentum_2d(x1, x2, v1, v2):\n",
        "  v1 = beta * v1 + 0.2 * x1\n",
        "  v2 = beta * v2 + 4 * x2\n",
        "  return x1 - eta * v1, x2 - eta * v2, v1, v2\n",
        "\n",
        "eta, beta = 0.6, 0.5\n",
        "d2l.show_trace_2d(f_2d, d2l.train_2d(momentum_2d))"
      ],
      "metadata": {
        "id": "LrMvDaKlAwjX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eta, beta = 0.6, 0.25\n",
        "d2l.show_trace_2d(f_2d, d2l.train_2d(momentum_2d))"
      ],
      "metadata": {
        "id": "sYqj73ugA2C8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.set_figsize()\n",
        "betas = [0.95, 0.9, 0.6, 0]\n",
        "for beta in betas:\n",
        "  x = torch.arange(40).detach().numpy()\n",
        "  d2l.plt.plot(x, beta ** x, label=f'beta = {beta:.2f}')\n",
        "d2l.plt.xlabel('time')\n",
        "d2l.plt.legend();"
      ],
      "metadata": {
        "id": "5gc4lV54A4VU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.6.2 Practical Experiments"
      ],
      "metadata": {
        "id": "xPHXcfyZA8OQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_momentum_states(feature_dim):\n",
        "  v_w = torch.zeros((feature_dim, 1))\n",
        "  v_b = torch.zeros(1)\n",
        "  return (v_w, v_b)"
      ],
      "metadata": {
        "id": "Nmfd3C0pA8o1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sgd_momentum(params, states, hyperparams):\n",
        "  for p, v in zip(params, states):\n",
        "    with torch.no_grad():\n",
        "      v[:] = hyperparams['momentum'] * v + p.grad\n",
        "      p[:] -= hyperparams['lr'] * v\n",
        "    p.grad.data.zero_()"
      ],
      "metadata": {
        "id": "tBbd2QYWA_T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_momentum(lr, momentum, num_epochs=2):\n",
        "  d2l.train_ch11(sgd_momentum, init_momentum_states(feature_dim),\n",
        "    {'lr': lr, 'momentum': momentum}, data_iter,\n",
        "    feature_dim, num_epochs)\n",
        "\n",
        "data_iter, feature_dim = d2l.get_data_ch11(batch_size=10)\n",
        "train_momentum(0.02, 0.5)"
      ],
      "metadata": {
        "id": "k4xvmBaNBG_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_momentum(0.01, 0.9)"
      ],
      "metadata": {
        "id": "_2sugKhZBLtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_momentum(0.005, 0.9)"
      ],
      "metadata": {
        "id": "3lEDQa2tBO5b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = torch.optim.SGD\n",
        "d2l.train_concise_ch11(trainer, {'lr': 0.005, 'momentum': 0.9}, data_iter)"
      ],
      "metadata": {
        "id": "ChUXr4_DBQiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.6.3 Theoretical Analysis"
      ],
      "metadata": {
        "id": "VSnNW-zeBS1_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lambdas = [0.1, 1, 10, 19]\n",
        "eta = 0.1\n",
        "d2l.set_figsize((6, 4))\n",
        "for lam in lambdas:\n",
        "  t = torch.arange(20).detach().numpy()\n",
        "  d2l.plt.plot(t, (1 - eta * lam) ** t, label=f'lambda = {lam:.2f}')\n",
        "d2l.plt.xlabel('time')\n",
        "d2l.plt.legend();"
      ],
      "metadata": {
        "id": "R-itOACoBTqX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.7 Adagrad**\n",
        "\n",
        "11.7.1 Sparse Features and Learning Rates\n",
        "\n",
        "11.7.2 Preconditioning\n",
        "\n",
        "11.7.3 The Algorithm"
      ],
      "metadata": {
        "id": "ToE2mTgrBZMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def adagrad_2d(x1, x2, s1, s2):\n",
        "  eps = 1e-6\n",
        "  g1, g2 = 0.2 * x1, 4 * x2\n",
        "  s1 += g1 ** 2\n",
        "  s2 += g2 ** 2\n",
        "  x1 -= eta / math.sqrt(s1 + eps) * g1\n",
        "  x2 -= eta / math.sqrt(s2 + eps) * g2\n",
        "  return x1, x2, s1, s2\n",
        "\n",
        "def f_2d(x1, x2):\n",
        "  return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
        "\n",
        "eta = 0.4\n",
        "d2l.show_trace_2d(f_2d, d2l.train_2d(adagrad_2d))"
      ],
      "metadata": {
        "id": "gf8s_K7lBhDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eta = 2\n",
        "d2l.show_trace_2d(f_2d, d2l.train_2d(adagrad_2d))"
      ],
      "metadata": {
        "id": "tSv5Kku4BmGR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.7.4 Implementation from Scratch"
      ],
      "metadata": {
        "id": "LoCsHLokBoFr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_adagrad_states(feature_dim):\n",
        "  s_w = torch.zeros((feature_dim, 1))\n",
        "  s_b = torch.zeros(1)\n",
        "  return (s_w, s_b)\n",
        "\n",
        "def adagrad(params, states, hyperparams):\n",
        "  eps = 1e-6\n",
        "  for p, s in zip(params, states):\n",
        "    with torch.no_grad():\n",
        "      s[:] += torch.square(p.grad)\n",
        "      p[:] -= hyperparams['lr'] * p.grad / torch.sqrt(s + eps)\n",
        "    p.grad.data.zero_()"
      ],
      "metadata": {
        "id": "iP1pPuhlBmlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter, feature_dim = d2l.get_data_ch11(batch_size=10)\n",
        "d2l.train_ch11(adagrad, init_adagrad_states(feature_dim),\n",
        "    {'lr': 0.1}, data_iter, feature_dim);"
      ],
      "metadata": {
        "id": "N-O69XCzBxNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.7.5 Concise Implementation"
      ],
      "metadata": {
        "id": "QLLNlYSKBzzk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = torch.optim.Adagrad\n",
        "d2l.train_concise_ch11(trainer, {'lr': 0.1}, data_iter)"
      ],
      "metadata": {
        "id": "XVu8Gn7pB0Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.8 RMSProp**\n",
        "\n",
        "11.8.1 The Algorithm"
      ],
      "metadata": {
        "id": "o5dG4HufB33L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "d2l.set_figsize()\n",
        "gammas = [0.95, 0.9, 0.8, 0.7]\n",
        "for gamma in gammas:\n",
        "  x = torch.arange(40).detach().numpy()\n",
        "  d2l.plt.plot(x, (1-gamma) * gamma ** x, label=f'gamma = {gamma:.2f}')\n",
        "d2l.plt.xlabel('time');"
      ],
      "metadata": {
        "id": "ozj5DIAHB8yr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.8.2 Implementation from Scratch"
      ],
      "metadata": {
        "id": "DTLw-lsYCBhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsprop_2d(x1, x2, s1, s2):\n",
        "  g1, g2, eps = 0.2 * x1, 4 * x2, 1e-6\n",
        "  s1 = gamma * s1 + (1 - gamma) * g1 ** 2\n",
        "  s2 = gamma * s2 + (1 - gamma) * g2 ** 2\n",
        "  x1 -= eta / math.sqrt(s1 + eps) * g1\n",
        "  x2 -= eta / math.sqrt(s2 + eps) * g2\n",
        "  return x1, x2, s1, s2\n",
        "\n",
        "def f_2d(x1, x2):\n",
        "  return 0.1 * x1 ** 2 + 2 * x2 ** 2\n",
        "\n",
        "eta, gamma = 0.4, 0.9\n",
        "d2l.show_trace_2d(f_2d, d2l.train_2d(rmsprop_2d))"
      ],
      "metadata": {
        "id": "Fwe1mHh8B83h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_rmsprop_states(feature_dim):\n",
        "  s_w = torch.zeros((feature_dim, 1))\n",
        "  s_b = torch.zeros(1)\n",
        "  return (s_w, s_b)"
      ],
      "metadata": {
        "id": "WUDHXj2uCJKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def rmsprop(params, states, hyperparams):\n",
        "  gamma, eps = hyperparams['gamma'], 1e-6\n",
        "  for p, s in zip(params, states):\n",
        "    with torch.no_grad():\n",
        "      s[:] = gamma * s + (1 - gamma) * torch.square(p.grad)\n",
        "      p[:] -= hyperparams['lr'] * p.grad / torch.sqrt(s + eps)\n",
        "    p.grad.data.zero_()"
      ],
      "metadata": {
        "id": "KNoQZ475CLBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter, feature_dim = d2l.get_data_ch11(batch_size=10)\n",
        "d2l.train_ch11(rmsprop, init_rmsprop_states(feature_dim),\n",
        "    {'lr': 0.01, 'gamma': 0.9}, data_iter, feature_dim);"
      ],
      "metadata": {
        "id": "T655OCKsCQN_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.8.3 Concise Implementation"
      ],
      "metadata": {
        "id": "vSomCEoZCSuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = torch.optim.RMSprop\n",
        "d2l.train_concise_ch11(trainer, {'lr': 0.01, 'alpha': 0.9},\n",
        "    data_iter)"
      ],
      "metadata": {
        "id": "9L8ag1N3CTMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **11.9 Adadelta**\n",
        "\n",
        "11.9.1 The Algorithm\n",
        "\n",
        "11.9.2 Implementation"
      ],
      "metadata": {
        "id": "pnSZzrYfCYQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import torch\n",
        "from d2l import torch as d2l\n",
        "  def init_adadelta_states(feature_dim):\n",
        "    s_w, s_b = torch.zeros((feature_dim, 1)), torch.zeros(1)\n",
        "    delta_w, delta_b = torch.zeros((feature_dim, 1)), torch.zeros(1)\n",
        "    return ((s_w, delta_w), (s_b, delta_b))\n",
        "  \n",
        "  def adadelta(params, states, hyperparams):\n",
        "    rho, eps = hyperparams['rho'], 1e-5\n",
        "    for p, (s, delta) in zip(params, states):\n",
        "      with torch.no_grad():\n",
        "      # In-place updates via [:]\n",
        "        s[:] = rho * s + (1 - rho) * torch.square(p.grad)\n",
        "        g = (torch.sqrt(delta + eps) / torch.sqrt(s + eps)) * p.grad\n",
        "        p[:] -= g\n",
        "        delta[:] = rho * delta + (1 - rho) * g * g\n",
        "      p.grad.data.zero_()"
      ],
      "metadata": {
        "id": "knW92TroCVXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_iter, feature_dim = d2l.get_data_ch11(batch_size=10)\n",
        "d2l.train_ch11(adadelta, init_adadelta_states(feature_dim),\n",
        "    {'rho': 0.9}, data_iter, feature_dim);"
      ],
      "metadata": {
        "id": "6FK5PkL5CnvE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = torch.optim.Adadelta\n",
        "d2l.train_concise_ch11(trainer, {'rho': 0.9}, data_iter)"
      ],
      "metadata": {
        "id": "GpLew14_CqRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}